{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd ","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:34:08.501719Z","iopub.execute_input":"2022-06-15T16:34:08.502186Z","iopub.status.idle":"2022-06-15T16:34:08.531661Z","shell.execute_reply.started":"2022-06-15T16:34:08.502095Z","shell.execute_reply":"2022-06-15T16:34:08.530793Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/titanic/train.csv').set_index(\"PassengerId\")","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:34:25.213216Z","iopub.execute_input":"2022-06-15T16:34:25.213638Z","iopub.status.idle":"2022-06-15T16:34:25.243114Z","shell.execute_reply.started":"2022-06-15T16:34:25.213607Z","shell.execute_reply":"2022-06-15T16:34:25.242225Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train[-10:]","metadata":{"execution":{"iopub.status.busy":"2022-06-10T23:18:03.650155Z","iopub.execute_input":"2022-06-10T23:18:03.650554Z","iopub.status.idle":"2022-06-10T23:18:03.668596Z","shell.execute_reply.started":"2022-06-10T23:18:03.650508Z","shell.execute_reply":"2022-06-10T23:18:03.667631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We will star by creating the dataset \n\nX_train =  train.drop([\"Survived\"], axis=1)\ny_train = train[\"Survived\"].astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T23:30:57.95746Z","iopub.execute_input":"2022-06-10T23:30:57.957873Z","iopub.status.idle":"2022-06-10T23:30:57.965606Z","shell.execute_reply.started":"2022-06-10T23:30:57.957841Z","shell.execute_reply":"2022-06-10T23:30:57.964515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We will star by  using the Logistic regression model \nfrom sklearn.linear_model import LogisticRegression \n\n# We have some categorical data we need to \nX_train = X_train.drop(['Name','Sex', 'Ticket','Cabin',\"Embarked\"], axis = 1)\nX_train = X_train.fillna(0) # We fill the NaN\n","metadata":{"execution":{"iopub.status.busy":"2022-06-10T23:31:19.201121Z","iopub.execute_input":"2022-06-10T23:31:19.201569Z","iopub.status.idle":"2022-06-10T23:31:19.209525Z","shell.execute_reply.started":"2022-06-10T23:31:19.20152Z","shell.execute_reply":"2022-06-10T23:31:19.208578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We initiate the model \nmodel = LogisticRegression ()\nmodel.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T23:31:21.474303Z","iopub.execute_input":"2022-06-10T23:31:21.474715Z","iopub.status.idle":"2022-06-10T23:31:21.500751Z","shell.execute_reply.started":"2022-06-10T23:31:21.474681Z","shell.execute_reply":"2022-06-10T23:31:21.500125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now we wil evaluate \nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2022-06-10T23:32:56.322906Z","iopub.execute_input":"2022-06-10T23:32:56.323966Z","iopub.status.idle":"2022-06-10T23:32:56.328644Z","shell.execute_reply.started":"2022-06-10T23:32:56.323903Z","shell.execute_reply":"2022-06-10T23:32:56.327751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_train)\naccuracy_score(y_train, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T23:33:02.692495Z","iopub.execute_input":"2022-06-10T23:33:02.692877Z","iopub.status.idle":"2022-06-10T23:33:02.702905Z","shell.execute_reply.started":"2022-06-10T23:33:02.692847Z","shell.execute_reply":"2022-06-10T23:33:02.702248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We will use another model to improve the results \n\nfrom sklearn.tree import DecisionTreeClassifier \n\nmodel_1 = DecisionTreeClassifier()\nmodel_1.fit(X_train, y_train)\ny_pred = model_1.predict(X_train)\naccuracy_score(y_train, y_pred)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-10T23:35:24.339254Z","iopub.execute_input":"2022-06-10T23:35:24.339711Z","iopub.status.idle":"2022-06-10T23:35:24.356987Z","shell.execute_reply.started":"2022-06-10T23:35:24.339674Z","shell.execute_reply":"2022-06-10T23:35:24.355978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now we will make a prediction for the test data \n# First we will shape the test data as the train\n\nX_test = pd.read_csv(\"../input/titanic/test.csv\").set_index(\"PassengerId\")\n\nX_test = X_test.drop(['Name','Sex', 'Ticket','Cabin',\"Embarked\"], axis = 1)\nX_test = X_test.fillna(0) # We fill the NaN\n","metadata":{"execution":{"iopub.status.busy":"2022-06-10T23:38:50.145515Z","iopub.execute_input":"2022-06-10T23:38:50.145999Z","iopub.status.idle":"2022-06-10T23:38:50.161811Z","shell.execute_reply.started":"2022-06-10T23:38:50.145965Z","shell.execute_reply":"2022-06-10T23:38:50.160151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now it's time to predict with model_1 on the test data \n\ny_pred_test = model_1.predict(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-10T23:40:01.760864Z","iopub.execute_input":"2022-06-10T23:40:01.761323Z","iopub.status.idle":"2022-06-10T23:40:01.768875Z","shell.execute_reply.started":"2022-06-10T23:40:01.76129Z","shell.execute_reply":"2022-06-10T23:40:01.767568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We will create a function to make the csv file we need \n\ndef make_submission(X_test, y_pred_test, title):\n    submission = pd.DataFrame({\n        \"PassengerId\" : X_test.index, \n        \"Survived\" : y_pred_test\n    })\n    submission.to_csv(title, index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T23:44:21.316378Z","iopub.execute_input":"2022-06-10T23:44:21.316861Z","iopub.status.idle":"2022-06-10T23:44:21.322898Z","shell.execute_reply.started":"2022-06-10T23:44:21.316825Z","shell.execute_reply":"2022-06-10T23:44:21.322006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_submission(X_test, y_pred_test, 'submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-10T23:47:09.889654Z","iopub.execute_input":"2022-06-10T23:47:09.89011Z","iopub.status.idle":"2022-06-10T23:47:09.89913Z","shell.execute_reply.started":"2022-06-10T23:47:09.890076Z","shell.execute_reply":"2022-06-10T23:47:09.897954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The prediction we made was not good so we will try to improve by using the categorical data \n","metadata":{}},{"cell_type":"code","source":"# We will star by creating the dataset \n\nX_train =  train.drop([\"Survived\"], axis=1)\ny_train = train[\"Survived\"].astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:34:54.387851Z","iopub.execute_input":"2022-06-15T16:34:54.388247Z","iopub.status.idle":"2022-06-15T16:34:54.400453Z","shell.execute_reply.started":"2022-06-15T16:34:54.388216Z","shell.execute_reply":"2022-06-15T16:34:54.399196Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"X_train ","metadata":{"execution":{"iopub.status.busy":"2022-06-11T21:32:34.763717Z","iopub.execute_input":"2022-06-11T21:32:34.764112Z","iopub.status.idle":"2022-06-11T21:32:34.793558Z","shell.execute_reply.started":"2022-06-11T21:32:34.764082Z","shell.execute_reply":"2022-06-11T21:32:34.792727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We also need to check the test data so we can create a model that can be suited for both ","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('../input/titanic/test.csv').set_index(\"PassengerId\")\ntrain = pd.read_csv('../input/titanic/train.csv').set_index(\"PassengerId\")","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:35:08.628858Z","iopub.execute_input":"2022-06-15T16:35:08.629244Z","iopub.status.idle":"2022-06-15T16:35:08.652387Z","shell.execute_reply.started":"2022-06-15T16:35:08.629201Z","shell.execute_reply":"2022-06-15T16:35:08.651089Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# First we can see the Name, Ticket No are not useful so we will drop this as well as the Cabin since a lot of data is missing \n\nX_train = train.drop(['Name','Ticket', 'Cabin','Survived'], axis=1)\ny_train = (train['Survived'])\nX_test = test.drop(['Name','Ticket', 'Cabin'], axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:35:12.223390Z","iopub.execute_input":"2022-06-15T16:35:12.224138Z","iopub.status.idle":"2022-06-15T16:35:12.232347Z","shell.execute_reply.started":"2022-06-15T16:35:12.224103Z","shell.execute_reply":"2022-06-15T16:35:12.231492Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Now we will fill the data missing, first we will check where we have data missing \n\nimport missingno as msng \n\nmsng.matrix(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T22:04:05.275708Z","iopub.execute_input":"2022-06-11T22:04:05.276127Z","iopub.status.idle":"2022-06-11T22:04:05.56808Z","shell.execute_reply.started":"2022-06-11T22:04:05.276091Z","shell.execute_reply":"2022-06-11T22:04:05.567243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We need to fill the Age and Embarked columns. \n\nfill_age = X_train['Age'].mean()\n\nX_train[\"Age\"] = X_train['Age'].fillna(value= fill_age) # We fill the NaN\nX_train['Embarked'] = X_train['Embarked'].fillna(0)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:35:17.487871Z","iopub.execute_input":"2022-06-15T16:35:17.488572Z","iopub.status.idle":"2022-06-15T16:35:17.496321Z","shell.execute_reply.started":"2022-06-15T16:35:17.488531Z","shell.execute_reply":"2022-06-15T16:35:17.495508Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"msng.matrix(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T22:07:07.254204Z","iopub.execute_input":"2022-06-11T22:07:07.254769Z","iopub.status.idle":"2022-06-11T22:07:07.525318Z","shell.execute_reply.started":"2022-06-11T22:07:07.254738Z","shell.execute_reply":"2022-06-11T22:07:07.523618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We will check the unique values on the columns \nfor col in X_train:\n    print(X_train[col].unique())","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:35:23.853991Z","iopub.execute_input":"2022-06-15T16:35:23.854749Z","iopub.status.idle":"2022-06-15T16:35:23.868312Z","shell.execute_reply.started":"2022-06-15T16:35:23.854708Z","shell.execute_reply":"2022-06-15T16:35:23.867321Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# We observe the Embarked column is not correctly filled since we have a 0\n# We will use the S value since the S is the most common value \nX_train['Embarked']=X_train['Embarked'].replace(0,\"S\")\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:35:30.333172Z","iopub.execute_input":"2022-06-15T16:35:30.333644Z","iopub.status.idle":"2022-06-15T16:35:30.339682Z","shell.execute_reply.started":"2022-06-15T16:35:30.333609Z","shell.execute_reply":"2022-06-15T16:35:30.338658Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# We review the problem is solved \nfor col in X_train:\n    print(X_train[col].unique())","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:35:35.775424Z","iopub.execute_input":"2022-06-15T16:35:35.775866Z","iopub.status.idle":"2022-06-15T16:35:35.787608Z","shell.execute_reply.started":"2022-06-15T16:35:35.775832Z","shell.execute_reply":"2022-06-15T16:35:35.786417Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# We will do the same thing for the test data \n\nmsng.matrix(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T23:31:48.331258Z","iopub.execute_input":"2022-06-11T23:31:48.33174Z","iopub.status.idle":"2022-06-11T23:31:48.742799Z","shell.execute_reply.started":"2022-06-11T23:31:48.331709Z","shell.execute_reply":"2022-06-11T23:31:48.741829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# It seems our data can be filled easily since the missing data is all discrete type value \nfill_testa = X_test['Age'].mean()\nfill_testf = X_test['Fare'].mean()\nX_test [\"Age\"] = X_test[\"Age\"].fillna(value = fill_testa) # We fill the NaN\nX_test ['Fare'] = X_test['Fare'].fillna(value = fill_testf)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:35:44.916864Z","iopub.execute_input":"2022-06-15T16:35:44.917258Z","iopub.status.idle":"2022-06-15T16:35:44.925957Z","shell.execute_reply.started":"2022-06-15T16:35:44.917218Z","shell.execute_reply":"2022-06-15T16:35:44.924514Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# We check the unique values \n\nfor col in X_test:\n    print(X_test[col].unique())","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:35:48.378946Z","iopub.execute_input":"2022-06-15T16:35:48.379340Z","iopub.status.idle":"2022-06-15T16:35:48.391791Z","shell.execute_reply.started":"2022-06-15T16:35:48.379310Z","shell.execute_reply":"2022-06-15T16:35:48.390676Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# We can se the ranges of SibsP goes from [0-8] on both cases \n# however Parch have different range values [0-6] and [0-9]\n\nX_test['Parch'][X_test['Parch'] == 9]","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:35:55.496185Z","iopub.execute_input":"2022-06-15T16:35:55.496587Z","iopub.status.idle":"2022-06-15T16:35:55.506855Z","shell.execute_reply.started":"2022-06-15T16:35:55.496556Z","shell.execute_reply":"2022-06-15T16:35:55.505702Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# We are planning to use one hot encoding so we need to move this rows and recreate a result\n\nX_test_toadd = X_test.loc[[1234,1257] , :]","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:35:58.697133Z","iopub.execute_input":"2022-06-15T16:35:58.698312Z","iopub.status.idle":"2022-06-15T16:35:58.705875Z","shell.execute_reply.started":"2022-06-15T16:35:58.698255Z","shell.execute_reply":"2022-06-15T16:35:58.704795Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# We will add the rows to the end of the X_train data \nX_train = X_train.append(X_test_toadd, ignore_index = True)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:36:04.425959Z","iopub.execute_input":"2022-06-15T16:36:04.426382Z","iopub.status.idle":"2022-06-15T16:36:04.435231Z","shell.execute_reply.started":"2022-06-15T16:36:04.426349Z","shell.execute_reply":"2022-06-15T16:36:04.434164Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# We check the data at the end is added \nX_train","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:36:17.182805Z","iopub.execute_input":"2022-06-15T16:36:17.183312Z","iopub.status.idle":"2022-06-15T16:36:17.207728Z","shell.execute_reply.started":"2022-06-15T16:36:17.183241Z","shell.execute_reply":"2022-06-15T16:36:17.206892Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Now we will  provide the result of this two rows at the end of y_train \nto_add =[0,0]\ny_train = np.append(y_train, to_add)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:36:21.154234Z","iopub.execute_input":"2022-06-15T16:36:21.154777Z","iopub.status.idle":"2022-06-15T16:36:21.160325Z","shell.execute_reply.started":"2022-06-15T16:36:21.154744Z","shell.execute_reply":"2022-06-15T16:36:21.159281Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# We check the values are inside the vector correctly \nlen(y_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:41:38.261207Z","iopub.execute_input":"2022-06-15T16:41:38.262027Z","iopub.status.idle":"2022-06-15T16:41:38.267652Z","shell.execute_reply.started":"2022-06-15T16:41:38.261986Z","shell.execute_reply":"2022-06-15T16:41:38.266619Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Now it's time to \nfor col in X_train:\n    print(X_train[col].unique())","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:36:27.018874Z","iopub.execute_input":"2022-06-15T16:36:27.020000Z","iopub.status.idle":"2022-06-15T16:36:27.031204Z","shell.execute_reply.started":"2022-06-15T16:36:27.019955Z","shell.execute_reply":"2022-06-15T16:36:27.030231Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Now that the train data have the existance of the 9 Parch we will onehot encode \n# We will normalize as well \n\n# We will borrow some classes from Scikit-Learn \n# to normalize the data and use onehot encoder for the categorical classes\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\n\n# Create a column transformer to use the MinMaxScales and OnehotEncoder\nct= make_column_transformer(\n    (MinMaxScaler(), ['Age', 'Fare']), #turn all values in these columns between 0 and 1\n    (OneHotEncoder(handle_unknown=\"ignore\"), ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked'])\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:39:21.801214Z","iopub.execute_input":"2022-06-15T16:39:21.801625Z","iopub.status.idle":"2022-06-15T16:39:21.815189Z","shell.execute_reply.started":"2022-06-15T16:39:21.801595Z","shell.execute_reply":"2022-06-15T16:39:21.814382Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# We now fit the data \nct.fit(X_train)\n\n#We finally transform the X_train \nX_train_normal = ct.transform(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:39:25.133769Z","iopub.execute_input":"2022-06-15T16:39:25.134205Z","iopub.status.idle":"2022-06-15T16:39:25.165031Z","shell.execute_reply.started":"2022-06-15T16:39:25.134169Z","shell.execute_reply":"2022-06-15T16:39:25.164148Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# We need to convert the train data to pd.DataFrame again \nX_train_normal = X_train_normal.toarray()\nX_train_normal = pd.DataFrame(X_train_normal)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:42:12.991806Z","iopub.execute_input":"2022-06-15T16:42:12.992385Z","iopub.status.idle":"2022-06-15T16:42:13.015137Z","shell.execute_reply.started":"2022-06-15T16:42:12.992344Z","shell.execute_reply":"2022-06-15T16:42:13.013322Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:39:32.999001Z","iopub.execute_input":"2022-06-15T16:39:32.999460Z","iopub.status.idle":"2022-06-15T16:39:33.004873Z","shell.execute_reply.started":"2022-06-15T16:39:32.999425Z","shell.execute_reply":"2022-06-15T16:39:33.003525Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Now it's time to do it with the normalized test data \n# \nct.fit(X_test)\n\n#We finally transform the X_train \nX_test_normal = ct.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:40:10.143661Z","iopub.execute_input":"2022-06-15T16:40:10.144079Z","iopub.status.idle":"2022-06-15T16:40:10.167539Z","shell.execute_reply.started":"2022-06-15T16:40:10.144048Z","shell.execute_reply":"2022-06-15T16:40:10.166729Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# We need to convert the train data to pd.DataFrame again \nX_test_normal = X_test_normal.toarray()\nX_test_normal = pd.DataFrame(X_test_normal)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:40:12.219379Z","iopub.execute_input":"2022-06-15T16:40:12.219958Z","iopub.status.idle":"2022-06-15T16:40:12.224874Z","shell.execute_reply.started":"2022-06-15T16:40:12.219924Z","shell.execute_reply":"2022-06-15T16:40:12.223856Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"len(X_train_normal), len(y_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:43:54.967417Z","iopub.execute_input":"2022-06-15T16:43:54.968526Z","iopub.status.idle":"2022-06-15T16:43:54.978464Z","shell.execute_reply.started":"2022-06-15T16:43:54.968471Z","shell.execute_reply":"2022-06-15T16:43:54.975650Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# We will use rainforest classifier \nfrom sklearn.ensemble import RandomForestClassifier \n\nmodel_1 = RandomForestClassifier()\nmodel_1.fit(X_train_normal, y_train)\ny_pred = model_1.predict(X_train_normal)\naccuracy_score(y_train, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:44:29.351085Z","iopub.execute_input":"2022-06-15T16:44:29.351535Z","iopub.status.idle":"2022-06-15T16:44:29.625518Z","shell.execute_reply.started":"2022-06-15T16:44:29.351499Z","shell.execute_reply":"2022-06-15T16:44:29.624588Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"y_preds = model_1.predict(X_test_normal)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:17.494963Z","iopub.execute_input":"2022-06-15T16:45:17.495369Z","iopub.status.idle":"2022-06-15T16:45:17.525535Z","shell.execute_reply.started":"2022-06-15T16:45:17.495333Z","shell.execute_reply":"2022-06-15T16:45:17.524469Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def make_submission(X_test_normal, y_preds, title):\n    submission = pd.DataFrame({\n        \"PassengerId\" : X_test.index, \n        \"Survived\" : y_preds\n    })\n    submission.to_csv(title, index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:25.533694Z","iopub.execute_input":"2022-06-15T16:45:25.534099Z","iopub.status.idle":"2022-06-15T16:45:25.539610Z","shell.execute_reply.started":"2022-06-15T16:45:25.534066Z","shell.execute_reply":"2022-06-15T16:45:25.538691Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"make_submission(X_test_normal, y_preds, 'submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:46:16.680687Z","iopub.execute_input":"2022-06-15T16:46:16.681069Z","iopub.status.idle":"2022-06-15T16:46:16.689095Z","shell.execute_reply.started":"2022-06-15T16:46:16.681038Z","shell.execute_reply":"2022-06-15T16:46:16.688157Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"With these result we improved a little obtaining 0.73684  now we will try with another model \n","metadata":{}},{"cell_type":"code","source":"# We will use neural network with binary classifier \nimport tensorflow as tf \n# Lets recreate a model to fit on the training data and evaluate on the train test \n\n# Create the seed \ntf.random.set_seed(42)\n\n#Create the model (same as last model)\n\n#1. Create a model with a non-linear activation \nmodel_2 = tf.keras.Sequential([\n                                tf.keras.layers.Dense(7, activation=tf.keras.activations.relu),\n                                tf.keras.layers.Dense(5, activation=tf.keras.activations.relu),\n                                tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid)\n])\n\n#2. Compile the model \nmodel_2.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n                optimizer=tf.keras.optimizers.Adam(lr=0.01),\n                metrics=[\"Accuracy\"])\n\n#3. Fit the model \nmodel_2.fit(X_train_normal,y_train, epochs=100)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:50:54.106127Z","iopub.execute_input":"2022-06-15T16:50:54.106558Z","iopub.status.idle":"2022-06-15T16:51:12.521495Z","shell.execute_reply.started":"2022-06-15T16:50:54.106525Z","shell.execute_reply":"2022-06-15T16:51:12.520677Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"y_pred = model_2.predict(X_test_normal)\ny_pred = tf.round(y_pred)\ny_pred = tf.squeeze(y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T17:04:01.936601Z","iopub.execute_input":"2022-06-15T17:04:01.937140Z","iopub.status.idle":"2022-06-15T17:04:02.121917Z","shell.execute_reply.started":"2022-06-15T17:04:01.937095Z","shell.execute_reply":"2022-06-15T17:04:02.120807Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"make_submission(X_test_normal, y_preds, 'submission.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We've got a lower score of 0.55263","metadata":{}},{"cell_type":"code","source":"import catboost as cb \nmodel_3 = cb.CatBoostClassifier()\nmodel_3.fit(X_train_normal, y_train)\ny_pred = model_3.predict(X_train_normal)\naccuracy_score(y_train, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T17:14:31.327947Z","iopub.execute_input":"2022-06-15T17:14:31.328416Z","iopub.status.idle":"2022-06-15T17:14:32.893983Z","shell.execute_reply.started":"2022-06-15T17:14:31.328376Z","shell.execute_reply":"2022-06-15T17:14:32.893336Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"y_preds = model_3.predict(X_test_normal)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T17:19:18.329428Z","iopub.execute_input":"2022-06-15T17:19:18.330198Z","iopub.status.idle":"2022-06-15T17:19:18.338618Z","shell.execute_reply.started":"2022-06-15T17:19:18.330155Z","shell.execute_reply":"2022-06-15T17:19:18.337452Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"y_preds","metadata":{"execution":{"iopub.status.busy":"2022-06-15T17:19:28.658632Z","iopub.execute_input":"2022-06-15T17:19:28.659059Z","iopub.status.idle":"2022-06-15T17:19:28.667488Z","shell.execute_reply.started":"2022-06-15T17:19:28.659026Z","shell.execute_reply":"2022-06-15T17:19:28.666194Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"make_submission(X_test_normal, y_preds, 'submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-15T17:19:36.813147Z","iopub.execute_input":"2022-06-15T17:19:36.813567Z","iopub.status.idle":"2022-06-15T17:19:36.821678Z","shell.execute_reply.started":"2022-06-15T17:19:36.813535Z","shell.execute_reply":"2022-06-15T17:19:36.820581Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"The third model scored 0.77511 using bootcast ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}